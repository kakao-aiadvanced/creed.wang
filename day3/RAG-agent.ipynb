{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c1090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "tavily = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance\n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question,\n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\\n\\n document: {document} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"What is prompt?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prompt is a method used in prompt engineering, also known as in-context prompting, to communicate with language models (LLMs) to influence their behavior and achieve desired outcomes without altering the model's weights. This process involves experimentation and heuristics, as the effectiveness of prompts can vary significantly across different models. The primary goal of prompt engineering is to enhance alignment and steerability of the model.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\n",
    "    Use three sentences maximum and keep the answer concise\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"question: {question}\\n\\n context: {context} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"What is prompt?\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "system = \"\"\"You are a grader assessing whether\n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate\n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a\n",
    "    single key 'score' and no preamble or explanation.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"documents: {documents}\\n\\n answer: {generation} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: bool\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def docs_retrieval(state):\n",
    "    print(\"1. DOCS RETRIEVE\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question, \"web_search\": False}\n",
    "\n",
    "def relevance_checker(state):\n",
    "    print(\"2. RELEVANCE CHECKER\")\n",
    "    documents = state[\"documents\"]\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score[\"score\"]\n",
    "        if grade.lower() == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    print(\"3. DECIDE TO GENERATE\")\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    if len(documents) == 0:\n",
    "        print(\"  USE WEB SEARCH\")\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        print(\"  GO TO GENERATE\")\n",
    "        return \"generate\"\n",
    "\n",
    "def search_tavily(state):\n",
    "    print(\"3-1. SEARCH TAVILY\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    search_results = tavily.search(query=question, max_results=3)['results']\n",
    "    documents = []\n",
    "    for search_result in search_results:\n",
    "        document = Document(\n",
    "            page_content=search_result[\"content\"],\n",
    "            metadata={\"source\": search_result[\"url\"], \"title\": search_result[\"title\"]}\n",
    "        )\n",
    "        documents.append(document)\n",
    "    return {\"documents\": documents, \"question\": question, \"web_search\": True}\n",
    "\n",
    "def generate_answer(state):\n",
    "    print(\"4. GENERATE ANSWER\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def hallucination_checker(state):\n",
    "    print(\"5. HALLUCINATION CHECKER\")\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"  NO HALLUCINATION\")\n",
    "        return \"success\"\n",
    "    else:\n",
    "        print(\"  HALLUCINATION FOUND\")\n",
    "        return \"failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"docs_retrieval\", docs_retrieval)\n",
    "workflow.add_node(\"relevance_checker\", relevance_checker)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "workflow.add_node(\"search_tavily\", search_tavily)\n",
    "\n",
    "workflow.set_entry_point(\"docs_retrieval\")\n",
    "workflow.add_edge(\"docs_retrieval\", \"relevance_checker\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_checker\",\n",
    "    decide_to_generate,\n",
    "    {\"websearch\": \"search_tavily\", \"generate\": \"generate_answer\"}\n",
    ")\n",
    "workflow.add_edge(\"search_tavily\", \"relevance_checker\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_answer\",\n",
    "    hallucination_checker,\n",
    "    {\"success\": END, \"failed\": \"generate_answer\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DOCS RETRIEVE\n",
      "Finished running: docs_retrieval\n",
      "2. RELEVANCE CHECKER\n",
      "3. DECIDE TO GENERATE\n",
      "  GO TO GENERATE\n",
      "Finished running: relevance_checker\n",
      "4. GENERATE ANSWER\n",
      "5. HALLUCINATION CHECKER\n",
      "  NO HALLUCINATION\n",
      "Finished running: generate_answer\n",
      "\n",
      "\n",
      "---\n",
      "generation: A prompt is a method used in prompt engineering, also known as In-Context Prompting, to communicate with language models (LLMs) to influence their behavior and achieve desired outcomes without altering the model's weights. This process involves experimentation and heuristics, as the effectiveness of prompts can vary significantly across different models. The primary goal of prompt engineering is to enhance alignment and steerability of the models.\n",
      "sources: https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/,https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/,https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/,https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\n",
      "titles: Prompt Engineering | Lil'Log,Prompt Engineering | Lil'Log,Prompt Engineering | Lil'Log,Prompt Engineering | Lil'Log\n"
     ]
    }
   ],
   "source": [
    "app = workflow.compile()\n",
    "\n",
    "inputs = {\"question\": \"What is prompt?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Finished running: {key}\")\n",
    "documents = value[\"documents\"]\n",
    "sources = \",\".join([document.metadata[\"source\"] for document in documents])\n",
    "titles = \",\".join([document.metadata[\"title\"] for document in documents])\n",
    "print(\"\\n\\n---\")\n",
    "print(\"generation: \" + value[\"generation\"])\n",
    "print(\"sources: \" + sources)\n",
    "print(\"titles: \" + titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiadvanced",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
